# ğŸ“˜ StudyBuddy â€” RAG PDF Q&A Chatbot.

Retrieval-Augmented Generation (RAG) chatbot for PDF Q&amp;A with a working FastAPI backend, FAISS indexer, LLM reasoning layer, and a Streamlit GUI. 

StudyBuddy is an intelligent PDF Q&A assistant that combines **semantic search** with **LLM reasoning**.
Upload your lecture notes or readings and ask natural-language questions, StudyBuddy retrieves the most
relevant chunks and generates **cited, grounded answers**.

## ğŸš€ Features
- ğŸ” **Retrieval-Augmented Generation (RAG):** FAISS-based vector search over chunked PDF text.
- ğŸ§  **LLM Integration:** Uses FLAN-T5-XL for context aware answers.
- ğŸ“š **Citation Support:** Every response includes exact PDF references for transparency.
- ğŸ–¥ï¸ **Streamlit Front-End:** Simple, clean, asthetically pleasing drag-and-drop UI for upload, ingest, and chat.
- âš™ï¸ **FastAPI Backend:** Modular endpoints for ingesting, searching, and answering.

## ğŸ—ï¸ Project Structure
- Main.py # Bootstrap / environment setup.
- api.py # FastAPI endpoints.
- GUI.py # Streamlit chat interface.
- pdfToChunks.py # PDF parsing + semantic chunking.
- VectorDB.py # FAISS index creation + retrieval.
- LLM.py # Model loading + response generation.
- trainingBuilding.py # Fine-tuning / training scripts.

## ğŸ“¦ Tech Stack

Python â€¢ FIASS â€¢ Json â€¢ Pickle â€¢ numpy â€¢ Hugging Face Transformers â€¢ Pytorch â€¢ OS
Path â€¢ Math â€¢ pypdf â€¢ pytesseract â€¢ pdf2image â€¢ subprocess â€¢ shutil â€¢ re â€¢ time 
Hugging Face Sentence Transformers â€¢ streamlit â€¢ requests â€¢ fastapi â€¢ pydantic 


## ğŸ§© Example Query
Q: â€œWhat are the main goals of an operating system?â€â€¨
A: Convenience for users and efficient system operation.â€¨Citations: Operating_Systems_Week1.pdf, Slide 54, Operating_Systems_Week1.pdf, Slide 55, Operating_Systems_Week1.pdf, Slide 56

## ğŸ“ˆ Model Evaluation

| Metric | Value |
|--------|--------|
| Eval Loss | **1.182** |
| Perplexity | **3.26** |
| Eval Runtime | 11.5 s |
| Samples / sec | 34.0 |
| Steps / sec | 4.26 |

The fine-tuned FLAN-T5 model achieved a **perplexity of 3.26**, showing strong comprehension of uploaded PDF text.
This demonstrates that the RAG pipeline (FAISS + LLM) effectively grounds answers in the retrieved context while maintaining fluent, accurate generation.
